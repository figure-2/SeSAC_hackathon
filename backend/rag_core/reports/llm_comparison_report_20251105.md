# LLM 답변 품질 비교 보고서

## 1. 실험 개요

-   **날짜**: 2025-11-05
-   **질의 세트**: `5_evaluation/assets/queries.yaml` (4개 대표 질의)
-   **Retriever/Reranker**: `retrieve_k=20`, `rerank_k=7` 고정
-   **비교 대상**
    -   **Polyglot**: `EleutherAI/polyglot-ko-1.3b` (로컬)
    -   **Gemini**: `gemini-1.5-pro-latest` (Gemini API)

## 2. 정성 비교 요약

| 평가 항목 | Polyglot 1.3B | Gemini 1.5 Pro | 개선 효과 |
| :--- | :--- | :--- | :--- |
| **답변 완성도** | 의미 없는 단어/문장을 반복하며 답변 생성 자체에 실패하는 경우가 대부분. | 질문 의도에 맞는 완결된 문장을 논리적으로 생성. | **매우 높음** |
| **요약 정확도** | 참고 자료의 핵심 내용을 파악하지 못하고 무의미한 텍스트 나열. | 여러 참고 자료에서 핵심 논지를 정확히 찾아내고 종합하여 요약. | **매우 높음** |
| **자료 부족 대응** | (확인 불가, 답변 자체가 붕괴됨) | "참고 자료에 해당 내용이 없다"고 명확하고 안전하게 응답하여 환각 방지. | **매우 높음** |
| **지시 수행력** | (확인 불가, 기본 답변 생성도 어려움) | 단순 프롬프트만으로도 논리적인 답변을 생성하며, 지시 수행력이 높을 것으로 기대됨. | **높음 (예상)** |

## 3. 대표 질의별 비교 (상세 내용은 `5_evaluation/results/qualitative` 폴더 참조)

### 질문 1: 임진왜란은 언제 발발했어? (`ex_001`)
-   **Polyglot 답변**: 답변 생성 실패 (`되었습니다. 해서는 성했나?`)
-   **Gemini 답변**: 참고 자료 기반 "1592년 음력 4월 13일"이라고 명확히 답변.

### 질문 2: 세종대왕이 한글을 반포한 해는 언제야? (`ex_002`)
-   **Polyglot 답변**: 의미 없는 단어 나열로 답변 붕괴.
-   **Gemini 답변**: "제공된 참고 자료에는... 정보가 언급되어 있지 않습니다." 라며 안전하게 응답.

### 질문 3: 태조 왕건이 29명의 부인을 맞이한 이유는 무엇인가요? (`kr_001`)
-   **Polyglot 답변**: 답변 생성 실패 (`않는 하게 되지않는 것은...`)
-   **Gemini 답변**: "흩어져 있던 호족 세력을 하나로 모으고 고려를 통치하기 위한 정략혼인"이라고 핵심 원인 정확히 요약.

### 질문 4: 궁예가 나주를 점령하려고 한 이유는 무엇인가요? (`kr_002`)
-   **Polyglot 답변**: 답변 생성 실패 (`을 것은 [고려의 내용에서도...`)
-   **Gemini 답변**: 경제적, 외교적, 군사적 이유 세 가지로 구조화하여 논리적으로 설명.

## 4. 결론 및 후속 계획

-   **핵심 개선 사항**: LLM을 `polyglot-1.3b`에서 `Gemini 1.5 Pro` API로 교체하여 답변의 완성도, 정확성, 안전성, 논리력이 비약적으로 향상됨. RAG 파이프라인의 병목이 LLM 성능이었음을 입증함.
-   **남은 기술 부채**: `HuggingFaceEmbeddings`의 `DeprecationWarning` 해결 필요.
-   **차후 아이디어**: CoT 등 프롬프트 고도화, `gemini-1.5-flash` 모델과의 비용-성능 비교 분석.
